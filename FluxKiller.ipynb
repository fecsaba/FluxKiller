{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fecsaba/FluxKiller/blob/main/FluxKiller.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySxq3Vct8woP"
      },
      "source": [
        "\n",
        "# **Flux killer**\n",
        "### Notes\n",
        "- Uncheck `UPDATE_COMFY_UI`, and `USE_COMFYUI_MANAGER` and `INSTALL_GGUF_NODE` after first run if `USE_GOOGLE_DRIVE` is checked.\n",
        "\n",
        "#### Crystools\n",
        "\n",
        "### EasyUse\n",
        "A ComfyUI haszn√°lhat√≥s√°g√°nak jav√≠t√°sa √©rdek√©ben sz√°mos gyakran haszn√°lt csom√≥ponthoz optimaliz√°ltak √©s integr√°ltak.\n",
        "### ITools\n",
        "Az iTools n√©h√°ny √©letmin≈ës√©g-csom√≥pont, mint p√©ld√°ul a k√©p l√©trehoz√°s√°hoz haszn√°lt lehets√©ges prompt beolvas√°sa, a prompt f√°jlba ment√©se √∫j sork√©nt, a promptok beolvas√°sa t√∂bbsoros f√°jlb√≥l.\n",
        "\n",
        "### ComfyUI-Detail-Daemon\n",
        "A Muerrilla sd-webui-Detail-Daemon portja a ComfyUI csom√≥pontjak√©nt, a szigm√°k be√°ll√≠t√°s√°hoz, amelyek √°ltal√°ban jav√≠tj√°k a r√©szleteket, √©s esetleg elt√°vol√≠tj√°k a nem k√≠v√°nt bokeh- vagy h√°tt√©relmos√≥d√°st, k√ºl√∂n√∂sen a Flux modellekn√©l (de m≈±k√∂dik SDXL, SD1.5 √©s val√≥sz√≠n≈±leg m√°s modellek). Ha az √©rt√©keket t√∫l messzire viszi, az t√∫l√©les √©s/vagy HDR hat√°st eredm√©nyez. Itt n√©gy csom√≥pont tal√°lhat√≥. A Multiply Sigma √©s a Lying Sigma Sampler szint√©n szerepelnek a r√©szletek √°ltal√°nos jav√≠t√°s√°nak alternat√≠v m√≥dszereik√©nt.\n",
        "\n",
        "Detail Daemon Sampler\n",
        "Detail Daemon Graph Sigmas (a szigm√°k be√°ll√≠t√°s√°nak vizu√°lis √°br√°zol√°s√°hoz)\n",
        "Szigm√°k szorz√°sa (hontalan)\n",
        "Hazug Sigma Sampler\n",
        "Vegye figyelembe, hogy a Detail Daemon √©s a Lying Sigma Sampler csom√≥pontok alap√©rtelmez√©s szerint olyan egy√©ni mintavev≈ë csom√≥pontokkal m≈±k√∂dnek, mint p√©ld√°ul a SamplerCustomAdvanced. Ha nem egy√©ni mintavev≈ë csom√≥pontokkal szeretn√© haszn√°lni ≈ëket, p√©ld√°ul KSamplera vagy KSamplerAdvanced, akkor l√©tre kell hoznia egy egy√©ni mintavev≈ë-el≈ëbe√°ll√≠t√°st a BlehSetSamplerPresetcsom√≥pont seg√≠ts√©g√©vel, √≠gy kiv√°laszthatja az el≈ëre be√°ll√≠tott √©rt√©ket a mintavev≈ë csom√≥pontban tal√°lhat√≥ list√°b√≥l, az itt le√≠rtak szerint .\n",
        "\n",
        "### Rgthree Comfy\n",
        "Csom√≥pontok: Seed, Reroute, Context, Lora Loader Stack, Context Switch, Fast Muter. Ezek az egy√©ni csom√≥pontok seg√≠tenek megszervezni az √∂sszetett munkafolyamatok fel√©p√≠t√©s√©t.\n",
        "\n",
        "#### ComfyUI's ControlNet Auxiliary Preprocessors\n",
        "Plug-and-play ComfyUI csom√≥pontk√©szletek ControlNet tippk√©pek k√©sz√≠t√©s√©hez\n",
        "\"anime st√≠lus, tiltakoz√°s az utc√°n, cyberpunk v√°ros, egy r√≥zsasz√≠n haj√∫, arany szem≈± n≈ë (n√©zi a n√©z≈ët) egy t√°bl√°t tart a \"ComfyUI ControlNet Aux\" felirattal f√©lk√∂v√©r, neonr√≥zsasz√≠nnel a Flux.1 Dev-n\n",
        "A k√≥d m√°sol√°s-beilleszt√©se a https://github.com/lllyasviel/ControlNet/tree/main/annotator megfelel≈ë mapp√°ib√≥l, √©s csatlakoztatva van a ü§ó Hubhoz .\n",
        "\n",
        "<!-- #### Was node suite\n",
        "Csom√≥pontcsomag a ComfyUI-hoz sz√°mos √∫j csom√≥ponttal, p√©ld√°ul k√©pfeldolgoz√°ssal, sz√∂vegfeldolgoz√°ssal √©s egyebekkel.\n",
        "\n",
        "\n",
        "#### ComfyUI ControlAltAI Nodes\n",
        "Fluxus mintavev≈ë\n",
        "A Flux Sampler csom√≥pont egyetlen, √°ramvonalas csom√≥pontban egyes√≠ti a CustomSamplerAdvance csom√≥pont √©s a bemeneti csom√≥pontok funkci√≥it.\n",
        "\n",
        "CFG be√°ll√≠t√°s: A CFG fix √©rt√©ke 1.\n",
        "Kondicion√°l√°s bemenet: Csak pozit√≠v kondicion√°l√°s t√°mogatott.\n",
        "Kompatibilit√°s: Csak a Flux modellel kompatibilis mintavev≈ëket √©s √ºtemez≈ëket tartalmazza.\n",
        "L√°tens kompatibilit√°s: Csak SD3 √ºres l√°tens k√©pet haszn√°ljon. A norm√°l √ºres l√°tens k√©pcsom√≥pont nem kompatibilis.\n",
        "\n",
        "## Florence2 in ComfyUI\n",
        "A Florence-2 egy fejlett l√°t√°salap-modell, amely azonnali alap√∫ megk√∂zel√≠t√©st alkalmaz a l√°t√°s √©s a l√°t√°snyelvi feladatok sz√©les sk√°l√°j√°nak kezel√©s√©re. A Florence-2 k√©pes √©rtelmezni az egyszer≈± sz√∂veges felsz√≥l√≠t√°sokat olyan feladatok v√©grehajt√°s√°hoz, mint a feliratoz√°s, az objektum√©szlel√©s √©s a szegment√°l√°s. Haszn√°lja ki FLD-5B adatk√©szlet√ºnket, amely 5,4 milli√°rd megjegyz√©st tartalmaz 126 milli√≥ k√©pen, hogy elsaj√°t√≠tsa a t√∂bbfeladatos tanul√°st. A modell sorozatr√≥l-szekvenci√°ra architekt√∫r√°ja lehet≈ëv√© teszi, hogy mind a nulla l√∂v√©s, mind a finomhangolt be√°ll√≠t√°sokban kiv√°l√≥ legyen, √≠gy versenyk√©pes l√°t√°salapmodellnek bizonyul. -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdSgPE-S-qF2"
      },
      "source": [
        "# INIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Psbxbq7y77hM",
        "outputId": "6e1a3912-8a86-4c67-eb98-2d31d4b4c548"
      },
      "outputs": [],
      "source": [
        "# Sz√∂veg sz√≠nei:\n",
        "\n",
        "# \\033[30m - Fekete\n",
        "\n",
        "# \\033[31m - Piros\n",
        "\n",
        "# \\033[32m - Z√∂ld\n",
        "\n",
        "# \\033[33m - S√°rga\n",
        "\n",
        "# \\033[34m - K√©k\n",
        "\n",
        "# \\033[35m - Lila (Magenta)\n",
        "\n",
        "# \\033[36m - Ci√°n\n",
        "\n",
        "# \\033[37m - Vil√°gos Sz√ºrke\n",
        "\n",
        "# \\033[90m - S√∂t√©t Sz√ºrke\n",
        "\n",
        "# \\033[91m - Vil√°gos Piros\n",
        "\n",
        "# \\033[92m - Vil√°gos Z√∂ld\n",
        "\n",
        "# \\033[93m - Vil√°gos S√°rga\n",
        "\n",
        "# \\033[94m - Vil√°gos K√©k\n",
        "\n",
        "# \\033[95m - Vil√°gos Lila (Magenta)\n",
        "\n",
        "# \\033[96m - Vil√°gos Ci√°n\n",
        "\n",
        "# \\033[97m - Feh√©r\n",
        "\n",
        "# H√°tt√©r sz√≠nei:\n",
        "\n",
        "# \\033[40m - Fekete h√°tt√©r\n",
        "\n",
        "# \\033[41m - Piros h√°tt√©r\n",
        "\n",
        "# \\033[42m - Z√∂ld h√°tt√©r\n",
        "\n",
        "# \\033[43m - S√°rga h√°tt√©r\n",
        "\n",
        "# \\033[44m - K√©k h√°tt√©r\n",
        "\n",
        "# \\033[45m - Lila (Magenta) h√°tt√©r\n",
        "\n",
        "# \\033[46m - Ci√°n h√°tt√©r\n",
        "\n",
        "# \\033[47m - Vil√°gos Sz√ºrke h√°tt√©r\n",
        "\n",
        "# \\033[100m - S√∂t√©t Sz√ºrke h√°tt√©r\n",
        "\n",
        "# \\033[101m - Vil√°gos Piros h√°tt√©r\n",
        "\n",
        "# \\033[102m - Vil√°gos Z√∂ld h√°tt√©r\n",
        "\n",
        "# \\033[103m - Vil√°gos S√°rga h√°tt√©r\n",
        "\n",
        "# \\033[104m - Vil√°gos K√©k h√°tt√©r\n",
        "\n",
        "# \\033[105m - Vil√°gos Lila (Magenta) h√°tt√©r\n",
        "\n",
        "# \\033[106m - Vil√°gos Ci√°n h√°tt√©r\n",
        "\n",
        "# \\033[107m - Feh√©r h√°tt√©r\n",
        "\n",
        "# Vissza√°ll√≠t√°s (mind sz√≠nre, mind st√≠lusra): \\033[0m\n",
        "# INIT\n",
        "# #@title Environment Setup\n",
        "from pathlib import Path\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = False  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
        "INSTALL_GGUF_NODE = True  #@param {type:\"boolean\"}\n",
        "INSTALL_CUSTOM_NODES_DEPENDENCIES = True  #@param {type:\"boolean\"}\n",
        "\n",
        "OPTIONS.update({\n",
        "    'USE_GOOGLE_DRIVE': USE_GOOGLE_DRIVE,\n",
        "    'UPDATE_COMFY_UI': UPDATE_COMFY_UI,\n",
        "    'USE_COMFYUI_MANAGER': USE_COMFYUI_MANAGER,\n",
        "    'INSTALL_GGUF_NODE': INSTALL_GGUF_NODE,\n",
        "    'INSTALL_CUSTOM_NODES_DEPENDENCIES': INSTALL_CUSTOM_NODES_DEPENDENCIES\n",
        "})\n",
        "\n",
        "current_dir = !pwd\n",
        "WORKSPACE = f\"{current_dir[0]}/ComfyUI\"\n",
        "TEMP_MODELS_DIR = f\"{current_dir[0]}/temp_models/\"\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "# Cser√©ld le a val√≥s ComfyUI √∫tvonalra!\n",
        "comfyui_path = WORKSPACE  \n",
        "\n",
        "os.environ['COMFYUI_PATH'] = comfyui_path\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "\n",
        "!chmod -R 755 $WORKSPACE\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !chmod 755 .ci/**/*.bat .ci/**/*.py .ci/**/*.txt\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip3 install accelerate einops transformers>=4.28.1 safetensors>=0.4.2 aiohttp pyyaml Pillow scipy tqdm psutil tokenizers>=0.13.3\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip3 install torchsde kornia>=0.7.1 spandrel soundfile sentencepiece\n",
        "\n",
        "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "  !chmod 755 ComfyUI-Manager/**/*.sh\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "if OPTIONS['INSTALL_GGUF_NODE']:\n",
        "  %cd $WORKSPACE/custom_nodes\n",
        "  !git clone https://github.com/city96/ComfyUI-GGUF\n",
        "  !pip install -r ComfyUI-GGUF/requirements.txt\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "!echo -= Install custom nodes dependencies =-\n",
        "!pip install GitPython\n",
        "!python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n",
        "\n",
        "!echo -= Install nodes =-\n",
        "!echo -= **************** =-\n",
        "!echo -= Install Crystools =-\n",
        "%cd $WORKSPACE/custom_nodes\n",
        "!git clone https://github.com/crystian/ComfyUI-Crystools.git\n",
        "!pip install -r ComfyUI-Crystools/requirements.txt\n",
        "\n",
        "!echo -= Install EasyUse =-\n",
        "%cd $WORKSPACE/custom_nodes\n",
        "!git clone https://github.com/yolain/ComfyUI-Easy-Use.git\n",
        "!pip install -r ComfyUI-Easy-Use/requirements.txt\n",
        "\n",
        "\n",
        "def install_custom_node(comfyui_path, repo_url, node_folder_name):\n",
        "    custom_nodes_path = os.path.join(comfyui_path, \"custom_nodes\")\n",
        "\n",
        "    if not os.path.exists(custom_nodes_path):\n",
        "        os.makedirs(custom_nodes_path)\n",
        "    print(f\"custom_nodes mappa el√©r√©si √∫tvonala: {custom_nodes_path}\")\n",
        "\n",
        "    destination_path = os.path.join(custom_nodes_path, node_folder_name)\n",
        "\n",
        "    if not os.path.exists(destination_path):\n",
        "        !git clone {repo_url} {destination_path}\n",
        "        print(f\"{node_folder_name} telep√≠t√©se k√©sz.\")\n",
        "    else:\n",
        "        print(f\"{node_folder_name} m√°r telep√≠tve van.\")\n",
        "\n",
        "    requirements_path = os.path.join(destination_path, \"requirements.txt\")\n",
        "    if os.path.exists(requirements_path):\n",
        "        !pip install -r {requirements_path}\n",
        "        print(\"Dependenci√°k telep√≠tve.\")\n",
        "    else:\n",
        "        print(\"Nincs requirements.txt f√°jl, nem sz√ºks√©ges dependenci√°kat telep√≠teni.\")\n",
        "\n",
        "comfyui_path = \"/content/drive/MyDrive/ComfyUI\"\n",
        "# # iTools\n",
        "# repo_url = \"https://github.com/fecsaba/ComfyUI-iTools.git\"\n",
        "# node_folder_name = \"ComfyUI-iTools\"\n",
        "\n",
        "# install_custom_node(comfyui_path, repo_url, node_folder_name)\n",
        "\n",
        "# # Was node suite\n",
        "# repo_url = \"https://github.com/WASasquatch/was-node-suite-comfyui.git\"\n",
        "# node_folder_name = \"was-node-suite-comfyui\"\n",
        "\n",
        "# install_custom_node(comfyui_path, repo_url, node_folder_name)\n",
        "\n",
        "# ComfyUI's ControlNet Auxiliary Preprocessors\n",
        "repo_url = \"https://github.com/Fannovel16/comfyui_controlnet_aux.git\"\n",
        "node_folder_name = \"comfyui_controlnet_aux\"\n",
        "\n",
        "# install_custom_node(comfyui_path, repo_url, node_folder_name)\n",
        "\n",
        "# # ComfyUI ControlAltAI Nodes\n",
        "# repo_url = \"https://github.com/gseth/ControlAltAI-Nodes.git\"\n",
        "# node_folder_name = \"ControlAltAI-Nodes\"\n",
        "\n",
        "# install_custom_node(comfyui_path, repo_url, node_folder_name)\n",
        "\n",
        "# ComfyUI RgThree Nodes\n",
        "repo_url = \"https://github.com/rgthree/rgthree-comfy.git\"\n",
        "node_folder_name = \"rgthree-comfy\"\n",
        "\n",
        "install_custom_node(comfyui_path, repo_url, node_folder_name)\n",
        "\n",
        "# ComfyUI-Detail-Daemon\n",
        "repo_url = \"https://github.com/Jonseed/ComfyUI-Detail-Daemon.git\"\n",
        "node_folder_name = \"ComfyUI-Detail-Daemon\"\n",
        "\n",
        "# install_custom_node(comfyui_path, repo_url, node_folder_name)\n",
        "# # Florence2\n",
        "# repo_url = \"https://github.com/kijai/ComfyUI-Florence2.git\"\n",
        "# node_folder_name = \"ComfyUI-Florence2\"\n",
        "\n",
        "# install_custom_node(comfyui_path, repo_url, node_folder_name)\n",
        "\n",
        "%cd $WORKSPACE\n",
        "print(\"Telep√≠t√©s befejezve. Ind√≠tsd √∫jra a ComfyUI-t!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMsrFbZE_M30"
      },
      "source": [
        "# Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import hashlib\n",
        "import shlex\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "def is_valid_file(filepath, expected_hash=None):\n",
        "    \"\"\"Ellen≈ërzi a f√°jlt (pl. hash alapj√°n).\n",
        "       Ha expected_hash None, akkor az ellen≈ërz√©st kihagyja.\"\"\"\n",
        "    if not os.path.isfile(filepath):\n",
        "        print(f\"Figyelmeztet√©s: A '{filepath}' nem f√°jl.\")\n",
        "        return False\n",
        "    if expected_hash is None:\n",
        "        print(f\"T√°j√©koztat√°s: A '{filepath}' f√°jlt √°tugorjuk, mivel nincs hash ellen≈ërz√©s.\")\n",
        "        return True\n",
        "    try:\n",
        "        sha256_hash = hashlib.sha256()\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            while True:\n",
        "                chunk = f.read(4096)\n",
        "                if not chunk:\n",
        "                    break\n",
        "                sha256_hash.update(chunk)\n",
        "        if sha256_hash.hexdigest() == expected_hash:\n",
        "            print(f\"T√°j√©koztat√°s: A '{filepath}' f√°jl hash √©rt√©ke megegyezik a v√°rttal.\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Figyelmeztet√©s: A '{filepath}' f√°jl hash √©rt√©ke nem egyezik meg a v√°rttal.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Hiba a hash ellen≈ërz√©skor: {e}\")\n",
        "        return False\n",
        "\n",
        "def create_symbolic_links(source_dir, target_dirs):\n",
        "    \"\"\"L√©trehozza a szimbolikus linkeket a f√°jlokhoz.\n",
        "\n",
        "       source_dir: A forr√°sk√∂nyvt√°r √∫tvonala.\n",
        "       target_dirs: Egy lista, a c√©lk√∂nyvt√°rak √∫tvonalaival.\n",
        "    \"\"\"\n",
        "\n",
        "    for filename in os.listdir(source_dir):\n",
        "        source_path = os.path.join(source_dir, filename)\n",
        "        for target_dir in target_dirs:\n",
        "            target_path = os.path.join(target_dir, filename)\n",
        "            try:\n",
        "                os.makedirs(target_dir, exist_ok=True)  # C√©lk√∂nyvt√°rak l√©trehoz√°sa (ha nem l√©tezik)\n",
        "                os.symlink(source_path, target_path)  # Szimbolikus link l√©trehoz√°sa\n",
        "                print(f\"Szimbolikus link l√©trehozva: {source_path} -> {target_path}\")\n",
        "            except FileExistsError:\n",
        "                print(f\"A c√©lf√°jl m√°r l√©tezik: {target_path}. A szimbolikus linket nem hoztuk l√©tre\")\n",
        "            except Exception as e:\n",
        "                print(f\"Hiba a link l√©trehoz√°sakor: {e}\")\n",
        "\n",
        "\n",
        "def download_file(url, target_dir, filename, wget_params=None, expected_hash=None, downloaded_files=None):\n",
        "    \"\"\"Let√∂lt egy f√°jlt a megadott URL-r≈ël.\n",
        "        url: A let√∂ltend≈ë f√°jl URL-je.\n",
        "        target_dir: A c√©lk√∂nyvt√°r √∫tvonala.\n",
        "        filename: A let√∂lt√∂tt f√°jl neve.\n",
        "        wget_params: Opcion√°lis wget param√©terek stringk√©nt.\n",
        "        expected_hash: Opcion√°lis hash ellen≈ërz√©s\n",
        "        downloaded_files: A let√∂lt√∂tt f√°jlok list√°ja\n",
        "        \"\"\"\n",
        "    target_path = os.path.join(target_dir, filename)\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    if downloaded_files and target_path in downloaded_files:\n",
        "        print(f\"T√°j√©koztat√°s: A '{target_path}' f√°jl m√°r l√©tezik, ellen≈ërz√©se folyamatban.\")\n",
        "        if is_valid_file(target_path, expected_hash):\n",
        "            print(f\"T√°j√©koztat√°s: A '{target_path}' f√°jl √©rv√©nyes, a let√∂lt√©s √°tugorva.\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Figyelmeztet√©s: A '{target_path}' f√°jl √©rv√©nytelen. A f√°jl √∫jrat√∂lt√©se k√∂vetkezik.\")\n",
        "\n",
        "    if wget_params is None:\n",
        "        wget_params = \"\"\n",
        "\n",
        "\n",
        "    wget_command_parts = [\"wget\", \"-c\", url, wget_params, \"-O\", target_path]\n",
        "    wget_command = shlex.join(wget_command_parts)\n",
        "    print(f\"T√°j√©koztat√°s: F√°jl let√∂lt√©se: {url} -> {target_path}\")\n",
        "    try:\n",
        "      start_time = time.time()\n",
        "      result = subprocess.run(wget_command, shell=True, capture_output=True, check=False)\n",
        "      end_time = time.time()\n",
        "\n",
        "      if result.returncode != 0:\n",
        "          print(f\"Hiba a f√°jl let√∂lt√©sekor: {result.stderr.decode()}\")\n",
        "          return False\n",
        "      if is_valid_file(target_path, expected_hash):\n",
        "            print(f\"T√°j√©koztat√°s: F√°jl sikeresen let√∂ltve √©s ellen≈ërizve: {target_path} (id≈ë: {end_time-start_time:.2f}s)\")\n",
        "            if downloaded_files is not None:\n",
        "                downloaded_files[target_path] = True\n",
        "            return True\n",
        "      else:\n",
        "            print(f\"Figyelmeztet√©s: A f√°jl '{target_path}' √©rv√©nytelen, a let√∂lt√©s sikeres, de az ellen≈ërz√©s nem siker√ºlt. (id≈ë: {end_time-start_time:.2f}s)\")\n",
        "            return False\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Hiba a f√°jl let√∂lt√©sekor: {e}\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_directory = \"/content/downloaded_files\"  # A let√∂lt√©si c√©lk√∂nyvt√°r\n",
        "    file_list = [\n",
        "           {\n",
        "               \"url\": \"https://huggingface.co/SG161222/RealVisXL_V5.0_Lightning/resolve/main/RealVisXL_V5.0_Lightning_fp16.safetensors\",\n",
        "                \"filename\": \"RealVisXL_V5.0_Lightning_fp16.safetensors\",\n",
        "                \"expected_hash\": None,\n",
        "                \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            # sdxl_vae.safetensors save vae\n",
        "            {\n",
        "            \"url\": \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",\n",
        "             \"filename\": \"sdxl_vae.safetensors\",\n",
        "            \"expected_hash\": None,\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            # Download the FLUX model from Hugging Face and save it in the ./models/unet directory\n",
        "            {\n",
        "                \"url\": \"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf\",\n",
        "                \"filename\": \"flux1-dev-Q4_K_S.gguf\",\n",
        "                 \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            # Download the CLIP T5 model from Hugging Face and save it in ./models/clip\n",
        "            {\n",
        "                \"url\": \"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q4_K_S.gguf\",\n",
        "                \"filename\": \"t5-v1_1-xxl-encoder-Q4_K_S.gguf\",\n",
        "                 \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            # Download the safetensors file for the CLIP model\n",
        "            {\n",
        "                \"url\": \"https://huggingface.co/f5aiteam/CLIP/resolve/main/clip_l.safetensors\",\n",
        "                \"filename\": \"clip_l.safetensors\",\n",
        "                 \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            # Download the VAE model from Hugging Face and save it in ./models/vae\n",
        "            {\n",
        "                \"url\": \"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\",\n",
        "                \"filename\": \"ae.safetensors\",\n",
        "                 \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            # # Download the ControlNet models save models/controlnet\n",
        "            # If you want to use a specific ControlNet model, remove the hashtag (#) from the corresponding line.\n",
        "            {\n",
        "                \"url\": \"https://huggingface.co/XLabs-AI/flux-controlnet-depth-v3/resolve/main/flux-depth-controlnet-v3.safetensors\",\n",
        "                \"filename\": \"flux-depth-controlnet-v3.safetensors\",\n",
        "                 \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            {\n",
        "                \"url\": \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-canny-controlnet-v3.safetensors\",\n",
        "                \"filename\": \"flux-canny-controlnet-v3.safetensors\",\n",
        "                 \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "            {\n",
        "                \"url\": \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-hed-controlnet-v3.safetensors\",\n",
        "                \"filename\": \"flux-hed-controlnet-v3.safetensors\",\n",
        "                 \"wget_params\": \"--no-check-certificate\"\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    downloaded_files = {}\n",
        "    for file_info in file_list:\n",
        "        url = file_info[\"url\"]\n",
        "        filename = file_info[\"filename\"]\n",
        "        wget_params = file_info.get(\"wget_params\")\n",
        "        expected_hash = file_info.get(\"expected_hash\")\n",
        "        download_file(url, download_directory, filename, wget_params, expected_hash, downloaded_files)\n",
        "\n",
        "    # Szimbolikus link l√©trehoz√°sa a let√∂lt√∂tt f√°jlokhoz\n",
        "    link_target_directories = [\"/content/target_dir_1\", \"/content/target_dir_2\",\"/content/target_dir_3\"]\n",
        "    create_symbolic_links(download_directory, link_target_directories)\n",
        "\n",
        "    # A teszt mappa elt√°vol√≠t√°sa\n",
        "    #shutil.rmtree(download_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import hashlib\n",
        "import shlex\n",
        "\n",
        "def is_valid_file(filepath, expected_hash=None):\n",
        "    \"\"\"Ellen≈ërzi a f√°jlt (pl. hash alapj√°n).\n",
        "       Ha expected_hash None, akkor az ellen≈ërz√©st kihagyja.\"\"\"\n",
        "    if not os.path.isfile(filepath):\n",
        "        print(f\"Figyelmeztet√©s: A '{filepath}' nem f√°jl.\")\n",
        "        return False\n",
        "    if expected_hash is None:\n",
        "        print(f\"T√°j√©koztat√°s: A '{filepath}' f√°jlt √°tugorjuk, mivel nincs hash ellen≈ërz√©s.\")\n",
        "        return True\n",
        "    try:\n",
        "        sha256_hash = hashlib.sha256()\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            while True:\n",
        "                chunk = f.read(4096)\n",
        "                if not chunk:\n",
        "                    break\n",
        "                sha256_hash.update(chunk)\n",
        "        if sha256_hash.hexdigest() == expected_hash:\n",
        "            print(f\"T√°j√©koztat√°s: A '{filepath}' f√°jl hash √©rt√©ke megegyezik a v√°rttal.\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Figyelmeztet√©s: A '{filepath}' f√°jl hash √©rt√©ke nem egyezik meg a v√°rttal.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Hiba a hash ellen≈ërz√©skor: {e}\")\n",
        "        return False\n",
        "\n",
        "def download_file(url, target_dir, filename, wget_params=None, expected_hash=None):\n",
        "    \"\"\"Let√∂lt egy f√°jlt a megadott URL-r≈ël.\n",
        "        url: A let√∂ltend≈ë f√°jl URL-je.\n",
        "        target_dir: A c√©lk√∂nyvt√°r √∫tvonala.\n",
        "        filename: A let√∂lt√∂tt f√°jl neve.\n",
        "        wget_params: Opcion√°lis wget param√©terek stringk√©nt.\n",
        "        expected_hash: Opcion√°lis hash ellen≈ërz√©s\n",
        "        \"\"\"\n",
        "    target_path = os.path.join(target_dir, filename)\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    if wget_params is None:\n",
        "        wget_params = \"\"\n",
        "\n",
        "    wget_command_parts = [\"wget\", \"-c\", url, wget_params, \"-O\", target_path]\n",
        "    wget_command = shlex.join(wget_command_parts)\n",
        "\n",
        "    print(f\"T√°j√©koztat√°s: F√°jl let√∂lt√©se: {url} -> {target_path}\")\n",
        "\n",
        "    try:\n",
        "        subprocess.run(wget_command, check=True, shell=True, capture_output=True)\n",
        "        if is_valid_file(target_path, expected_hash):\n",
        "            print(f\"T√°j√©koztat√°s: F√°jl sikeresen let√∂ltve √©s ellen≈ërizve: {target_path}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Figyelmeztet√©s: A f√°jl '{target_path}' √©rv√©nytelen, a let√∂lt√©s sikeres, de az ellen≈ërz√©s nem siker√ºlt.\")\n",
        "            return False\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Hiba a f√°jl let√∂lt√©sekor: {e.stderr.decode()}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_directory = \"/content/downloaded_files\"  # A let√∂lt√©si c√©lk√∂nyvt√°r\n",
        "    file_list = [\n",
        "        # SDXL Model save models/checkpoints\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/SG161222/RealVisXL_V5.0_Lightning/resolve/main/RealVisXL_V5.0_Lightning_fp16.safetensors\",\n",
        "            \"filename\": \"RealVisXL_V5.0_Lightning_fp16.safetensors\",\n",
        "            \"expected_hash\": None,\n",
        "            \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        # sdxl_vae.safetensors save vae\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",\n",
        "            \"filename\": \"sdxl_vae.safetensors\",\n",
        "            \"expected_hash\": None,\n",
        "            \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        # Download the FLUX model from Hugging Face and save it in the ./models/unet directory\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf\",\n",
        "            \"filename\": \"flux1-dev-Q4_K_S.gguf\",\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        # Download the CLIP T5 model from Hugging Face and save it in ./models/clip\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q4_K_S.gguf\",\n",
        "            \"filename\": \"t5-v1_1-xxl-encoder-Q4_K_S.gguf\",\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        # Download the safetensors file for the CLIP model\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/f5aiteam/CLIP/resolve/main/clip_l.safetensors\",\n",
        "            \"filename\": \"clip_l.safetensors\",\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        # Download the VAE model from Hugging Face and save it in ./models/vae\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\",\n",
        "            \"filename\": \"ae.safetensors\",\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        # # Download the ControlNet models save models/controlnet\n",
        "        # If you want to use a specific ControlNet model, remove the hashtag (#) from the corresponding line.\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/XLabs-AI/flux-controlnet-depth-v3/resolve/main/flux-depth-controlnet-v3.safetensors\",\n",
        "            \"filename\": \"flux-depth-controlnet-v3.safetensors\",\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-canny-controlnet-v3.safetensors\",\n",
        "            \"filename\": \"flux-canny-controlnet-v3.safetensors\",\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "        {\n",
        "            \"url\": \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-hed-controlnet-v3.safetensors\",\n",
        "            \"filename\": \"flux-hed-controlnet-v3.safetensors\",\n",
        "             \"wget_params\": \"--no-check-certificate\"\n",
        "        },\n",
        "    ]\n",
        "    for file_info in file_list:\n",
        "        url = file_info[\"url\"]\n",
        "        filename = file_info[\"filename\"]\n",
        "        wget_params = file_info.get(\"wget_params\")\n",
        "        expected_hash = file_info.get(\"expected_hash\")\n",
        "        download_file(url, download_directory, filename, wget_params, expected_hash)\n",
        "    # A teszt mappa elt√°vol√≠t√°sa\n",
        "    #shutil.rmtree(download_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1EODhZPq_ejc",
        "outputId": "405e5e86-1bf8-4ced-bbc8-c98fc5757f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading resources...\n",
            "Downloading models...\n",
            "Google drive True\n",
            "/content/temp_models/\n",
            "Downloading resources...\n",
            "Downloading models...\n",
            "Google drive True\n",
            "\u001b[93m models mappa m√°r l√©tezik \u001b[0m\n",
            "file_path: /content/temp_models/sdxl_vae.safetensors\n",
            "file_path: /content/drive/MyDrive/ComfyUI/models/vae/sdxl_vae.safetensors\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "### Download Resources\n",
        "# def download_model(model_url, model_name, model_path, wget_params, sha_sum):\n",
        "#     if not os.path.exists(f\"{TEMP_MODELS_DIR}/{model_name}\"):\n",
        "#         file_path = os.path.join(TEMP_MODELS_DIR, model_name)\n",
        "#         os.system(f\"wget -c {model_url} -{wget_params} {file_path}\")\n",
        "#         hash = calculate_sha256_chunks(file_path)\n",
        "#         if hash == sha_sum:\n",
        "#             print(f\"\\033[32m{model_name} downloaded.\\033[0m\")\n",
        "#             os.system(f\"ln -s {file_path} {model_path}\")\n",
        "#         else:\n",
        "#             print(f\"\\033[31m{model_name} download failed.\\033[0m\")\n",
        "#             sys.exit(1)\n",
        "#     else:\n",
        "#         print(f\"\\033[93m{model_name} already downloaded.\\033[0m\")\n",
        "#         hash = calculate_sha256_chunks(file_path)\n",
        "#         if not hash == sha_sum:\n",
        "#             print(f\"\\033[31m{model_name} checksum failed.\\033[0m\")\n",
        "#             os.system(f\"rm {file_path}\")\n",
        "#             os.system(f\"wget -c {model_url} -{wget_params} {file_path}\")\n",
        "#         else:\n",
        "#             print(f\"\\033[32m{model_name} checksum passed.\\033[0m\")\n",
        "#             os.system(f\"unlink {model_path}\")\n",
        "#             os.system(f\"ln -s {file_path} {model_path}\")\n",
        "import sys\n",
        "### Download Resources\n",
        "def download_model(model_url, model_name, model_path, wget_params, sha_sum):\n",
        "    # Create the TEMP_MODELS_DIR directory if it doesn't exist\n",
        "    if not os.path.exists(TEMP_MODELS_DIR):\n",
        "        os.makedirs(TEMP_MODELS_DIR)\n",
        "\n",
        "    # Create the file path within TEMP_MODELS_DIR\n",
        "    file_path = TEMP_MODELS_DIR\n",
        "    print(f\"file_path: {file_path}{model_name}\")\n",
        "    print(f\"file_path: {model_path}\")\n",
        "\n",
        "    if not os.path.exists(file_path+model_name):\n",
        "        # Download the model\n",
        "        # os.system(f\"wget -c {model_url} -{wget_params} {file_path}\")\n",
        "        !wget -c \"{model_url}\" \"{wget_params}\" -O \"{os.path.join(file_path, model_name)}\"\n",
        "\n",
        "        # Calculate the SHA256 checksum of the downloaded file\n",
        "        if sha_sum == \"\":\n",
        "            hash = \"\"\n",
        "        else:\n",
        "            hash = calculate_sha256_chunks(file_path + model_name)\n",
        "        if hash == sha_sum:\n",
        "            print(f\"\\033[32m{model_name} downloaded.\\033[0m\")\n",
        "            # Create a symbolic link to the downloaded file in the desired model path\n",
        "            # os.system(f\"ln -s {file_path}{model_name} {model_path}\")\n",
        "            !ln -s \"{os.path.join(file_path, model_name)}\" \"{model_path}\"\n",
        "        else:\n",
        "            print(f\"\\033[31m{model_name} download failed.\\033[0m\")\n",
        "            sys.exit(1)\n",
        "\n",
        "def calculate_sha256_chunks(filename, chunk_size=4096):\n",
        "    \"\"\"\n",
        "    Chunkokban olvassa be a f√°jl tartalm√°t √©s kisz√°m√≠tja a hash-√©rt√©ket.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        sha256_hash = hashlib.sha256()\n",
        "        with open(filename, \"rb\") as f:\n",
        "            while True:\n",
        "                chunk = f.read(chunk_size)\n",
        "                if not chunk:\n",
        "                    break\n",
        "                sha256_hash.update(chunk)\n",
        "        return sha256_hash.hexdigest()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Hiba: A f√°jl '{filename}' nem tal√°lhat√≥.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"Downloading resources...\")\n",
        "print(\"Downloading models...\")\n",
        "print(f\"Google drive {OPTIONS['USE_GOOGLE_DRIVE']}\")\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    print(TEMP_MODELS_DIR)\n",
        "    print(\"Downloading resources...\")\n",
        "    print(\"Downloading models...\")\n",
        "    print(f\"Google drive {OPTIONS['USE_GOOGLE_DRIVE']}\")\n",
        "    if not os.path.exists(TEMP_MODELS_DIR):\n",
        "        os.makedirs(TEMP_MODELS_DIR)\n",
        "        print(\"\\033[32m models mappa l√©trehozva \\033[0m\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\033[93m models mappa m√°r l√©tezik \\033[0m\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # SDXL Model save models/checkpoints\n",
        "\n",
        "    download_model(\"https://huggingface.co/SG161222/RealVisXL_V5.0_Lightning/resolve/main/RealVisXL_V5.0_Lightning_fp16.safetensors\",\n",
        "                    \"RealVisXL_V5.0_Lightning_fp16.safetensors\", \n",
        "                    f\"{WORKSPACE}/models/checkpoint/RealVisXL_V5.0_Lightning_fp16.safetensors\", \n",
        "                    \"P\", \n",
        "                    \"\")\n",
        "    # !wget -c \"https://huggingface.co/SG161222/RealVisXL_V5.0_Lightning/resolve/main/RealVisXL_V5.0_Lightning_fp16.safetensors\" -O \"/content/models\"\n",
        "    # !ln -s \"/content/models/RealVisXL_V5.0_Lightning_fp16.safetensors\" \"./models/checkpoints/RealVisXL_V5.0_Lightning_fp16.safetensors\"\n",
        "\n",
        "    # sdxl_vae.safetensors\n",
        "    download_model(\"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",\n",
        "                   \"sdxl_vae.safetensors\", \n",
        "                   f\"{WORKSPACE}/models/vae/sdxl_vae.safetensors\",\n",
        "                   \"P\",\n",
        "                   \"63aeecb90ff7bc1c115395962d3e803571385b61938377bc7089b36e81e92e2e\")\n",
        "    # !wget -c \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\" -O \"/content/models\"\n",
        "    # !ln -s \"/content/models/sdxl_vae.safetensors\" \"./models/vae/sdxl_vae.safetensors\"\n",
        "\n",
        "    # # Download the FLUX model from Hugging Face and save it in the ./models/unet directory\n",
        "    download_model(\"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf\",\n",
        "                   \"flux1-dev-Q4_K_S.gguf\", \n",
        "                   f\"{WORKSPACE}/models/umet/flux1-dev-Q4_K_S.gguf\",\n",
        "                   \"P\",\n",
        "                   \"\")\n",
        "    # !wget -c \"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf\" -O \"/content/models\"\n",
        "    # !ln -s \"/content/models/flux1-dev-Q4_K_S.gguf\" \"./models/unet/flux1-dev-Q4_K_S.gguf\"\n",
        "    \n",
        "    # # Download the CLIP T5 model from Hugging Face and save it in ./models/clip\n",
        "    download_model(\"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q4_K_S.gguf\",\n",
        "                   \"t5-v1_1-xxl-encoder-Q4_K_S.gguf\", \n",
        "                   f\"{WORKSPACE}/models/clip/t5-v1_1-xxl-encoder-Q4_K_S.gguf\",\n",
        "                   \"P\",\n",
        "                   \"\")\n",
        "    # !wget -c \"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q4_K_S.gguf\" -P \"./models/clip\"\n",
        "\n",
        "    # # Download the safetensors file for the CLIP model\n",
        "    download_model(\"https://huggingface.co/f5aiteam/CLIP/resolve/main/clip_l.safetensors\",\n",
        "                   \"clip_l.safetensors\", \n",
        "                   f\"{WORKSPACE}/models/clip/clip_l.safetensors\",\n",
        "                   \"P\",\n",
        "                   \"\")\n",
        "    # !wget -c \"https://huggingface.co/f5aiteam/CLIP/resolve/main/clip_l.safetensors\" -P \"./models/clip\"\n",
        "\n",
        "    # # Download the VAE model from Hugging Face and save it in ./models/vae\n",
        "    download_model(\"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\",\n",
        "                   \"ae.safetensors\", \n",
        "                   f\"{WORKSPACE}/models/controlnet/ae.safetensors\",\n",
        "                   \"P\",\n",
        "                   \"\")\n",
        "    # !wget -c \"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\" -O \"/content/models\"\n",
        "    # !ln -s \"/content/models/ae.safetensors\" \"./models/vae/ae.safetensors\"\n",
        "\n",
        "    # # Download the ControlNet models\n",
        "    # # #If you want to use a specific ControlNet model, remove the hashtag (#) from the corresponding line.\n",
        "    download_model(\"https://huggingface.co/XLabs-AI/flux-controlnet-depth-v3/resolve/main/flux-depth-controlnet-v3.safetensors\",\n",
        "                   \"flux-depth-controlnet-v3.safetensors\", \n",
        "                   f\"{WORKSPACE}/models/controlnet/flux-depth-controlnet-v3.safetensors\",\n",
        "                   \"P\",\n",
        "                   \"\")\n",
        "    # !wget -c \"https://huggingface.co/XLabs-AI/flux-controlnet-depth-v3/resolve/main/flux-depth-controlnet-v3.safetensors\" -O \"/content/models\"\n",
        "    # !ln -s \"/content/models/flux-depth-controlnet-v3.safetensors\" \"./models/controlnet/flux-depth-controlnet-v3.safetensors\"\n",
        "    download_model(\"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-canny-controlnet-v3.safetensors\",\n",
        "                   \"flux-canny-controlnet-v3.safetensors\", \n",
        "                   f\"{WORKSPACE}/models/controlnet/flux-canny-controlnet-v3.safetensors\",\n",
        "                   \"P\",\n",
        "                   \"\")\n",
        "    # !wget -c \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-canny-controlnet-v3.safetensors\" -O \"/content/models\"\n",
        "    # !ln -s \"/content/models/flux-canny-controlnet-v3.safetensors\" \"./models/controlnet/flux-canny-controlnet-v3.safetensors\"\n",
        "    download_model(\"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-hed-controlnet-v3.safetensors\",\n",
        "                   \"flux-hed-controlnet-v3.safetensors\", \n",
        "                   f\"{WORKSPACE}/models/controlnet/flux-hed-controlnet-v3.safetensors\",\n",
        "                   \"P\",\n",
        "                   \"\")\n",
        "    # !wget -c \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-hed-controlnet-v3.safetensors\" -O \"/content/models\"\n",
        "    # !ln -s \"/content/models/flux-hed-controlnet-v3.safetensors\" \"./models/controlnet/flux-hed-controlnet-v3.safetensors\"\n",
        "\n",
        "else:\n",
        "    print(\"Downloading resources...\")\n",
        "    print(\"Downloading models...\")\n",
        "    print(f\"Google drive: {OPTIONS['USE_GOOGLE_DRIVE']}\")\n",
        "    # SDXL Model\n",
        "    !wget -c \"https://huggingface.co/SG161222/RealVisXL_V5.0_Lightning/resolve/main/RealVisXL_V5.0_Lightning_fp16.safetensors\" -P \"./models/checkpoints\"\n",
        "    # !wget -c \"https://huggingface.co/SG161222/RealVisXL_V5.0_Lightning/blob/main/RealVisXL_V5.0_Lightning_fp32.safetensors\" -P \"./models/checkpoints\"\n",
        "\n",
        "    # sdxl_vae.safetensors\n",
        "    !wget -c \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\" -P \"./models/vae\"\n",
        "\n",
        "    # Download the FLUX model from Hugging Face and save it in the ./models/unet directory\n",
        "    !wget -c \"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf\" -P \"./models/unet\"\n",
        "\n",
        "    # Download the CLIP T5 model from Hugging Face and save it in ./models/clip\n",
        "    !wget -c \"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q4_K_S.gguf\" -P \"./models/clip\"\n",
        "\n",
        "    # Download the safetensors file for the CLIP model\n",
        "    !wget -c \"https://huggingface.co/f5aiteam/CLIP/resolve/main/clip_l.safetensors\" -P \"./models/clip\"\n",
        "\n",
        "    # Download the VAE model from Hugging Face and save it in ./models/vae\n",
        "    !wget -c \"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\" -P \"./models/vae\"\n",
        "\n",
        "    # Download the ControlNet models\n",
        "    #If you want to use a specific ControlNet model, remove the hashtag (#) from the corresponding line.\n",
        "    !wget -c \"https://huggingface.co/XLabs-AI/flux-controlnet-depth-v3/resolve/main/flux-depth-controlnet-v3.safetensors\" -P \"./models/controlnet\"\n",
        "    !wget -c \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-canny-controlnet-v3.safetensors\" -P \"./models/controlnet\"\n",
        "    !wget -c \"https://huggingface.co/XLabs-AI/flux-controlnet-collections/resolve/main/flux-hed-controlnet-v3.safetensors\" -P \"./models/controlnet\"\n",
        "# **********************************************************************************************************************************\n",
        "# **********************************************************************************************************************************\n",
        "# **********************************************************************************************************************************\n",
        "# **********************************************************************************************************************************\n",
        "# !mkdir -p \"/content/models/\"\n",
        "# # SDXL model\n",
        "# !wget -c \"https://civitai.com/api/download/models/782002?type=Model&format=SafeTensor&size=full&fp=fp16\" -O \"/content/models/Juggernaut.safetensors\"\n",
        "# !ln -s \"/content/models/Juggernaut.safetensors\" \"./models/checkpoints/Juggernaut.safetensors\"\n",
        "\n",
        "# # diffusion_pytorch_model_promax\n",
        "# !wget -c \"https://huggingface.co/xinsir/controlnet-union-sdxl-1.0/resolve/main/diffusion_pytorch_model_promax.safetensors\" -O \"/content/models/diffusion_pytorch_model_promax.safetensors\"\n",
        "# !ln -s \"/content/models/diffusion_pytorch_model_promax.safetensors\" \"./models/checkpoints/diffusion_pytorch_model_promax.safetensors\"\n",
        "\n",
        "# # Download the FLUX model from Hugging Face and save it in the ./models/unet directory\n",
        "# !wget -c \"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/flux1-dev-Q4_K_S.gguf\" \"./models/unet/flux1-dev-Q4_K_S.gguf\"\n",
        "# # !ln -s \"/models/flux1-dev-Q8_0.gguf\" \"./models/unet/flux1-dev-Q8_0.gguf\"\n",
        "\n",
        "# # Download the CLIP T5 model from Hugging Face and save it in ./models/clip\n",
        "# !wget -c \"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q4_K_S.gguf\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/t5-v1_1-xxl-encoder-Q4_K_S.gguf\" \"./models/clip/t5-v1_1-xxl-encoder-Q4_K_S.gguf\"\n",
        "# # !ln -s \"/models/t5-v1_1-xxl-encoder-Q8_0.gguf\" \"./models/clip/t5-v1_1-xxl-encoder-Q8_0.gguf\"\n",
        "\n",
        "# # Download the safetensors file for the CLIP model\n",
        "# !wget -c \"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors?download=true\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/clip_l.safetensors\" \"./models/clip/clip_l.safetensors\"\n",
        "# # !ln -s \"/content/models/clip_l-for-gguf.safetensors\" \"./models/clip/clip_l-for-gguf.safetensors\"\n",
        "\n",
        "# # Download the VAE model from Hugging Face and save it in ./models/vae\n",
        "# !wget -c \"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/ae.safetensors\" \"./models/vae/ae.safetensors\"\n",
        "# # !ln -s \"/content/models/ae.safetensors\" \"./models/vae/ae.safetensors\"\n",
        "\n",
        "# # Download the diffusion model from Hugging Face and save it in ./models/controlnet\n",
        "# !wget -c \"https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro/resolve/main/diffusion_pytorch_model.safetensors?download=true\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/diffusion_pytorch_model.safetensors?download=true\" \"./models/controlnet/diffusion_pytorch_model.safetensors\"\n",
        "\n",
        "# Download the LoRa model from Civitai.com Replace `298eebac3e9fecdcd7def0c8a41fa14d` with your actual token\n",
        "# !wget -c \"https://civitai.com/api/download/models/1198851?type=Model&format=SafeTensor&token=298eebac3e9fecdcd7def0c8a41fa14d\" -O \"./models/loras/FluxThouS40k.safetensors\"\n",
        "# !wget -c \"https://civitai.com/api/download/models/1198851?type=Model&format=SafeTensor&token=298eebac3e9fecdcd7def0c8a41fa14d\" -O \"./models/loras/FluxThouS40k.safetensors\"\n",
        "# !wget -c \"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q4_K_S.gguf\" -P \"./models/unet\"\n",
        "# !wget -c \"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q4_K_S.gguf\" -P \"./models/clip\"\n",
        "# !wget -c \"https://huggingface.co/f5aiteam/CLIP/resolve/main/clip_l.safetensors\" -P \"./models/clip\"\n",
        "# !wget -c \"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\" -P \"./models/vae\"\n",
        "\n",
        "\n",
        "\n",
        "# %cd $WORKSPACE\n",
        "# Download the VAE model from Hugging Face and save it in ./models/vae\n",
        "# !wget -c \"https://huggingface.co/f5aiteam/VAE/resolve/main/ae.safetensors\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/ae.safetensors\" \"./models/vae/ae.safetensors\"\n",
        "# Download the diffusion model from Hugging Face and save it in ./models/controlnet\n",
        "# !wget -c \"https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro/resolve/main/diffusion_pytorch_model.safetensors?download=true\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/diffusion_pytorch_model.safetensors?download=true\" \"./models/controlnet/diffusion_pytorch_model.safetensors\"\n",
        "# Download the safetensors file for the CLIP model\n",
        "# !wget -c \"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors?download=true\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/clip_l.safetensors?download=true\" \"./models/clip/clip_l.safetensors\"\n",
        "# Download the CLIP T5 model from Hugging Face and save it in ./models/clip\n",
        "# !wget -c \"https://huggingface.co/city96/t5-v1_1-xxl-encoder-gguf/resolve/main/t5-v1_1-xxl-encoder-Q5_K_M.gguf?download=true\" -P \"/content/models\"\n",
        "# !ln -s \"/content/models/t5-v1_1-xxl-encoder-Q5_K_M.gguf?download=true\" \"./models/clip/t5-v1_1-xxl-encoder-Q5_K_M.gguf\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXOZnT80_tu0"
      },
      "source": [
        "### Run ComfyUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LUtZkx5q_wUn"
      },
      "outputs": [],
      "source": [
        "!wget -P ~ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i ~/cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BbFEe5MC5W0l"
      },
      "outputs": [],
      "source": [
        "\n",
        "!unlink /content/temp_models/sdxl_vae.safetensors\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
